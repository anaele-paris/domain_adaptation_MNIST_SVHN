{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CORAL APPROACH**\n",
    "---\n",
    "\n",
    "Sun, B., et al. \"Correlation alignment for unsupervised domain adaptation.\" In Domain Adaptation in Computer Vision Applications (pp. 153-171). Springer, Cham, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, Subset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# DEFINE DEVICE\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./svhn_data/train_32x32.mat\n",
      "MNIST mean: tensor([0.1307]), MNIST std: tensor([8.6270])\n",
      "SVHN mean: tensor([0.4377, 0.4438, 0.4728]), SVHN std: tensor([6.3370, 6.4325, 6.3052])\n",
      "Using downloaded and verified file: ./svhn_data/train_32x32.mat\n",
      "MNIST shape:  torch.Size([60000, 28, 28])\n",
      "SVHN shape:  (73257, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# GET COVARIANCE MATRICES\n",
    "\n",
    "#------------------------------------------------\n",
    "# Compute the MNIST and SVHN mean and standard \n",
    "# deviation on the training set\n",
    "#------------------------------------------------\n",
    "\n",
    "def calculate_mean(loader, num_channels):\n",
    "    \"\"\"Calculate the mean for each channel across the dataset.\"\"\"\n",
    "    channel_sum, num_elements = torch.zeros(num_channels), 0\n",
    "\n",
    "    for data, _ in loader:\n",
    "        channel_sum += data.mean([0, 2, 3]) * data.size(0)\n",
    "        num_elements += data.size(0)\n",
    "\n",
    "    mean = channel_sum / num_elements\n",
    "    return mean\n",
    "\n",
    "def calculate_std(loader, num_channels, mean):\n",
    "    \"\"\"Calculate the standard deviation for each channel across the dataset.\"\"\"\n",
    "    channel_squared_sum, num_elements = torch.zeros(num_channels), 0\n",
    "\n",
    "    for data, _ in loader:\n",
    "        batch_size = data.size(0)\n",
    "        num_elements += batch_size\n",
    "        for i in range(num_channels):\n",
    "            channel_squared_sum[i] += ((data[:, i, :, :] - mean[i])**2).sum()\n",
    "\n",
    "    variance = channel_squared_sum / num_elements\n",
    "    std = torch.sqrt(variance)\n",
    "    return std\n",
    "\n",
    "\n",
    "# Extract MNIST and SVHN datasets\n",
    "MNIST_train = datasets.MNIST(root='./mnist_data/', train=True, transform = transforms.ToTensor(), download=True)\n",
    "SVHN_train = datasets.SVHN(root='./svhn_data/', split='train', transform = transforms.ToTensor(), download=True)\n",
    "\n",
    "# Create DataLoaders for MNIST and SVHN datasets\n",
    "batch_size = 64  # Adjust as needed\n",
    "MNIST_train_loader = DataLoader(MNIST_train, batch_size=batch_size, shuffle=False)\n",
    "SVHN_train_loader = DataLoader(SVHN_train, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Compute mean and standard deviation for MNIST and SVHN datasets\n",
    "mnist_mean = calculate_mean(MNIST_train_loader, 1)\n",
    "mnist_std = calculate_std(MNIST_train_loader, 1, mnist_mean)\n",
    "print(f\"MNIST mean: {mnist_mean}, MNIST std: {mnist_std}\")\n",
    "\n",
    "svhn_mean = calculate_mean(SVHN_train_loader, 3)\n",
    "svhn_std = calculate_std(SVHN_train_loader, 3, svhn_mean)\n",
    "print(f\"SVHN mean: {svhn_mean}, SVHN std: {svhn_std}\")\n",
    "\n",
    "#------------------------------------------------\n",
    "# Normalise and flatten the MNIST and SVHN  dataset\n",
    "# with real mean and standard deviation\n",
    "#------------------------------------------------\n",
    "\n",
    "class FlattenTransform:\n",
    "    def __call__(self, x):\n",
    "        return x.view(-1)\n",
    "    \n",
    "transform_mnist = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize(mnist_mean, mnist_std),  # Normalize with real mean and standard deviation\n",
    "    FlattenTransform(),  # Flatten the images\n",
    "])\n",
    "\n",
    "transform_svhn = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(svhn_mean, svhn_std), # Normalize with real mean and standard deviation\n",
    "    FlattenTransform(),  # Flatten the images\n",
    "])\n",
    "\n",
    "MNIST_train_flat = datasets.MNIST(root='./mnist_data/', train=True, transform = transform_mnist, download=True)\n",
    "SVHN_train_flat = datasets.SVHN(root='./svhn_data/', split='train', transform = transform_svhn, download=True)\n",
    "\n",
    "MNIST_train_loader_flat = DataLoader(MNIST_train_flat, batch_size=batch_size, shuffle=False)\n",
    "SVHN_train_loader_flat = DataLoader(SVHN_train_flat, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"MNIST shape: \", MNIST_train_flat.data.shape)\n",
    "print(\"SVHN shape: \", SVHN_train_flat.data.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./svhn_data/train_32x32.mat\n",
      "Using downloaded and verified file: ./svhn_data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "# DOWNLOAD DATA \n",
    "\n",
    "# DOWNLOAD, RESIZE & NORMALIZE MNIST DATASET  (32x32x3 instead of originl 28x28x1)\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "# Define the transform to resize the image to 32x32 and replicate to 3 channels\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Resize to 32x32\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert to RGB by replicating channels\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize each channel (assuming mean 0.5, std 0.5 for simplicity)\n",
    "])\n",
    "\n",
    "# Download and load the dataset with the defined transform\n",
    "train_dataset_source = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
    "test_dataset_source = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=True)\n",
    "\n",
    "# DOWNLOAD, (RESIZE &) NORMALISE, SVHN DATASET (Stret View House Numbers)\n",
    "train_dataset_target = datasets.SVHN(root='./svhn_data/', split='train', transform=transform, download=True) # transform to insure same shape and normalisation\n",
    "test_dataset_target = datasets.SVHN(root='./svhn_data/', split='test', transform=transform, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# FUNCTIONS TO APPLY CORAL METHOD\n",
    "##########################################\n",
    "\n",
    "\n",
    "\n",
    "def compute_covariance_matrix(data):\n",
    "    \"\"\"\n",
    "    Compute the covariance matrix for the given data.\n",
    "    \n",
    "    :param data: 2D array where rows are samples and columns are features.\n",
    "    :return: Covariance matrix.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler(with_std=False)\n",
    "    data = scaler.fit_transform(data)  # Mean centering the data\n",
    "    covariance_matrix = np.cov(data, rowvar=False)\n",
    "    return covariance_matrix\n",
    "\n",
    "def coral(source_data, target_data):\n",
    "    \"\"\"\n",
    "    Perform CORAL on the source data to match the target data.\n",
    "    \n",
    "    :param source_data: Source data (MNIST) as a 2D numpy array.\n",
    "    :param target_data: Target data (SVHN) as a 2D numpy array.\n",
    "    :return: Transformed source data as a 2D numpy array.\n",
    "    \"\"\"\n",
    "    # Compute the covariance matrices\n",
    "    source_cov = compute_covariance_matrix(source_data)\n",
    "    target_cov = compute_covariance_matrix(target_data)\n",
    "\n",
    "    # Compute the source data whitening matrix\n",
    "    source_cov_eigvals, source_cov_eigvecs = np.linalg.eigh(source_cov)\n",
    "    source_whitening_matrix = np.dot(source_cov_eigvecs, np.diag(1.0 / np.sqrt(source_cov_eigvals)))\n",
    "    \n",
    "    # Compute the target data coloring matrix\n",
    "    target_cov_eigvals, target_cov_eigvecs = np.linalg.eigh(target_cov)\n",
    "    target_coloring_matrix = np.dot(target_cov_eigvecs, np.diag(np.sqrt(target_cov_eigvals)))\n",
    "\n",
    "    # Transform the source data\n",
    "    source_data_whitened = np.dot(source_data, source_whitening_matrix)\n",
    "    source_data_colored = np.dot(source_data_whitened, target_coloring_matrix)\n",
    "\n",
    "    return source_data_colored\n",
    "\n",
    "# Flatten the images and convert to numpy arrays\n",
    "def extract_features_and_flatten(dataset):\n",
    "    dataset_flattened = []\n",
    "    for data, _ in dataset:\n",
    "        # Flatten the image data and convert to a numpy array\n",
    "        data = data.numpy().flatten()\n",
    "        dataset_flattened.append(data)\n",
    "    return np.array(dataset_flattened)\n",
    "\n",
    "# Extract features from datasets\n",
    "source_features = extract_features_and_flatten(train_dataset_source)\n",
    "target_features = extract_features_and_flatten(train_dataset_target)\n",
    "\n",
    "# Apply CORAL to align the source dataset to the target dataset\n",
    "source_features_aligned = coral(source_features, target_features)\n",
    "\n",
    "# Convert the transformed features back into PyTorch tensors\n",
    "source_features_aligned_tensor = torch.tensor(source_features_aligned, dtype=torch.float32)\n",
    "\n",
    "# Here you would reshape the tensor and train your classifier using the aligned data\n",
    "# This part is not shown and would depend on your classifier training procedure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python WSL (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
